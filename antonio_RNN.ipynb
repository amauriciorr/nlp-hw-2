{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "970AS3pGerFA"
   },
   "source": [
    "# DS-GA 1011 Homework 2\n",
    "## N-Gram and Neural Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "jDFAcX6MerFB",
    "outputId": "e3408ecc-e255-43b9-80dd-cc8faa32fc8b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import string\n",
    "from collections import Counter\n",
    "import datetime as dt\n",
    "import pickle as pkl\n",
    "import os\n",
    "import json\n",
    "#import jsonlines\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    current_device = 'cuda'\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    path = 'gdrive/My Drive/'\n",
    "else:\n",
    "    current_device = 'cpu'\n",
    "    path = './'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BpLkEDTmerFE"
   },
   "source": [
    "## I. N-Gram Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UYZDUMjerFF"
   },
   "source": [
    "#### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mx4F7xByerFF"
   },
   "outputs": [],
   "source": [
    "def load_wikitext(filename='wikitext2-sentencized.json'):\n",
    "    if not os.path.exists(filename):\n",
    "        !wget \"https://nyu.box.com/shared/static/9kb7l7ci30hb6uahhbssjlq0kctr5ii4.json\" -O $filename\n",
    "    \n",
    "    datasets = json.load(open(filename, 'r'))\n",
    "    for name in datasets:\n",
    "        datasets[name] = [x.split() for x in datasets[name]]\n",
    "    vocab = list(set([t for ts in datasets['train'] for t in ts]))      \n",
    "    print(\"Vocab size: %d\" % (len(vocab)))\n",
    "    return datasets, vocab\n",
    "\n",
    "def perplexity(model, sequences):\n",
    "    n_total = 0\n",
    "    logp_total = 0\n",
    "    for sequence in sequences:\n",
    "        logp_total += model.sequence_logp(sequence)\n",
    "        n_total += len(sequence) + 1  \n",
    "    ppl = 2 ** (- (1.0 / n_total) * logp_total)  \n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVfI-rjyerFH"
   },
   "source": [
    "### Additive Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHRoN6lMerFI"
   },
   "outputs": [],
   "source": [
    "class NGramAdditive(object):\n",
    "    def __init__(self, n, delta, vsize):\n",
    "        self.n = n\n",
    "        self.delta = delta\n",
    "        self.count = defaultdict(lambda: defaultdict(float))\n",
    "        self.total = defaultdict(float)\n",
    "        self.vsize = vsize\n",
    "    \n",
    "    def estimate(self, sequences):\n",
    "        for sequence in sequences:\n",
    "            padded_sequence = ['<bos>']*(self.n-1) + sequence + ['<eos>']\n",
    "            for i in range(len(padded_sequence) - self.n+1):\n",
    "                ngram = tuple(padded_sequence[i:i+self.n])\n",
    "                prefix, word = ngram[:-1], ngram[-1]\n",
    "                self.count[prefix][word] += 1\n",
    "                self.total[prefix] += 1\n",
    "                \n",
    "    def sequence_logp(self, sequence):\n",
    "        padded_sequence = ['<bos>']*(self.n-1) + sequence + ['<eos>']\n",
    "        total_logp = 0\n",
    "        for i in range(len(padded_sequence) - self.n+1):\n",
    "            ngram = tuple(padded_sequence[i:i+self.n])\n",
    "            total_logp += np.log2(self.ngram_prob(ngram))\n",
    "        return total_logp\n",
    "\n",
    "    def ngram_prob(self, ngram):\n",
    "        prefix = ngram[:-1]\n",
    "        word = ngram[-1]\n",
    "        prob = ((self.delta + self.count[prefix][word]) / \n",
    "                (self.total[prefix] + self.delta*self.vsize))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlKfaPdBerFK",
    "outputId": "247f5bc5-825c-4728-9c86-28612b231c46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 33175\n",
      "Baseline (Additive smoothing, n=2, delta=0.0005)) Train Perplexity: 90.228\n",
      "Baseline (Additive smoothing, n=2, delta=0.0005)) Valid Perplexity: 525.825\n",
      "Baseline (Additive smoothing, n=3, delta=0.0005)) Train Perplexity: 26.768\n",
      "Baseline (Additive smoothing, n=3, delta=0.0005)) Valid Perplexity: 2577.128\n",
      "Baseline (Additive smoothing, n=4, delta=0.0005)) Train Perplexity: 19.947\n",
      "Baseline (Additive smoothing, n=4, delta=0.0005)) Valid Perplexity: 9570.901\n"
     ]
    }
   ],
   "source": [
    "wiki_datasets, vocab = load_wikitext()\n",
    "\n",
    "delta = 0.0005\n",
    "for n in [2, 3, 4]:\n",
    "    lm = NGramAdditive(n=n, delta=delta, vsize=len(vocab)+1)  # +1 is for <eos>\n",
    "    lm.estimate(wiki_datasets['train'])\n",
    "\n",
    "    print(\"Baseline (Additive smoothing, n=%d, delta=%.4f)) Train Perplexity: %.3f\" % (n, delta, perplexity(lm, wiki_datasets['train'])))\n",
    "    print(\"Baseline (Additive smoothing, n=%d, delta=%.4f)) Valid Perplexity: %.3f\" % (n, delta, perplexity(lm, wiki_datasets['valid'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T50510neerFN"
   },
   "source": [
    "### I.1 Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UN9rc5BperFO"
   },
   "outputs": [],
   "source": [
    "class NGramInterpolation(object):\n",
    "    def __init__(self, n, lambdas, vsize, total_word_count):\n",
    "        self.n = n\n",
    "        self.lambdas = lambdas\n",
    "        self.count = defaultdict(lambda: defaultdict(float))\n",
    "        self.total = defaultdict(float)\n",
    "        self.vsize = vsize\n",
    "        self.total_word_count = total_word_count\n",
    "        \n",
    "    \n",
    "    def estimate(self, sequences):\n",
    "        for sequence in sequences:\n",
    "            padded_sequence = ['<bos>']*(self.n-1) + sequence + ['<eos>']\n",
    "            for i in range(self.n-1, len(padded_sequence)):\n",
    "                ngram = tuple(padded_sequence[i-self.n+1:i+1])\n",
    "                for j in range(1, self.n):\n",
    "                    prefix, word = ngram[:j], ngram[j]\n",
    "                    self.count[prefix][word] += 1\n",
    "                    self.total[prefix] += 1 \n",
    "                    self.total[word] += 1\n",
    "                    \n",
    "    def sequence_logp(self, sequence):\n",
    "        padded_sequence = ['<bos>']*(self.n-1) + sequence + ['<eos>']\n",
    "        total_logp = 0\n",
    "        for i in range(len(padded_sequence) - self.n+1):\n",
    "            ngram = tuple(padded_sequence[i:i+self.n])\n",
    "            total_logp += np.log2(self.ngram_prob(ngram))\n",
    "        return total_logp\n",
    "\n",
    "    def ngram_prob(self, ngram):\n",
    "        prob = self.lambdas[-1]/self.vsize\n",
    "        word = ngram[-1]\n",
    "        prob += (self.total[word] / self.total_word_count) * self.lambdas[-2]\n",
    "        for nk in range(len(ngram) - 1):\n",
    "            prefix = ngram[nk:-1]\n",
    "            if self.total[prefix] > 1e-9:\n",
    "                prob += ((self.count[prefix][word])/ (self.total[prefix])) * self.lambdas[nk]\n",
    "            \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "or9C_sfGerFQ",
    "outputId": "6554e078-73ae-4a26-84d2-3abc03a80088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1924754\n"
     ]
    }
   ],
   "source": [
    "total_wc = len([t for ts in wiki_datasets['train'] for t in ts])\n",
    "print(total_wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Te3XJUyverFT"
   },
   "source": [
    "#### Results (showing $\\lambda_0,\\ldots,\\lambda_n$ values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rNaIztgJerFU",
    "outputId": "5e117ef4-b6d3-4311-cbc7-128a1d3a18d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas add to: 1.0\n",
      "lambdas = [0.20953827 0.79046173]\n",
      "Interpolation, n=2 | Train Perplexity: 262.011\n",
      "Interpolation, n=2 | Valid Perplexity: 516.755\n",
      "Lambdas add to: 0.9999999999999999\n",
      "lambdas = [0.25564492 0.49439094 0.24996414]\n",
      "Interpolation, n=3 | Train Perplexity: 18.841\n",
      "Interpolation, n=3 | Valid Perplexity: 170.144\n",
      "Lambdas add to: 1.0\n",
      "lambdas = [0.13951532 0.01370735 0.57312293 0.27365439]\n",
      "Interpolation, n=4 | Train Perplexity: 10.124\n",
      "Interpolation, n=4 | Valid Perplexity: 158.523\n",
      "A good configuration has been found\n"
     ]
    }
   ],
   "source": [
    "found = False\n",
    "while not(found):\n",
    "    perplexs = []\n",
    "    for n in [2, 3, 4]:\n",
    "        #lambdas = [1/(n+1) for i in range(n+1)]\n",
    "\n",
    "        # Uncomment to input in the following format #.##,#.##,#.##(...)\n",
    "        # lam = input()\n",
    "        # lambdas = [float(i) for i in lam.split(\",\")]\n",
    "\n",
    "        # Random search using Dirichlet Distribution (Notice: lambdas add to 1)\n",
    "        lambdas = np.ravel(np.random.dirichlet(np.ones(n),size=1))\n",
    "        print('Lambdas add to:',sum(np.ravel(np.random.dirichlet(np.ones(n),size=1))))\n",
    "\n",
    "        lm = NGramInterpolation(n=n, lambdas=lambdas, vsize=len(vocab)+1, total_word_count = total_wc)  # +1 is for <eos>\n",
    "        lm.estimate(wiki_datasets['train'])\n",
    "\n",
    "        print(\"lambdas = \" + str(lambdas))\n",
    "        print(\"Interpolation, n=%d | Train Perplexity: %.3f\" % (n, perplexity(lm, wiki_datasets['train'])))\n",
    "        print(\"Interpolation, n=%d | Valid Perplexity: %.3f\" % (n, perplexity(lm, wiki_datasets['valid'])))\n",
    "        perplexs.append(perplexity(lm, wiki_datasets['valid']))\n",
    "        \n",
    "        # If initial perplexity is not better than Additive Smoothing\n",
    "        if (n == 2) and perplexs[n-2] > 525:\n",
    "            break\n",
    "        \n",
    "        # If the next n-gram is not better than last one found\n",
    "        if ( n > 2 ):\n",
    "            if (perplexs[n-2] < perplexs[n-3]):\n",
    "                if n == 4:\n",
    "                    found = True\n",
    "                    print(\"A good configuration has been found\")\n",
    "                continue\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJSFMgxlerFl"
   },
   "source": [
    "## II. Neural Language Modeling with a Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A8adLmVCerFl"
   },
   "source": [
    "## LSTM RNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cpu\n",
      "Current path: ./\n"
     ]
    }
   ],
   "source": [
    "print('Current device: {}'.format(current_device))\n",
    "print('Current path: {}'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vl-TRA7CerFo"
   },
   "outputs": [],
   "source": [
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "def tokenize(document):\n",
    "    tokens = tokenizer(document)\n",
    "    tokens = [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvQEdk2eerFq"
   },
   "outputs": [],
   "source": [
    "def load_wikitext(fname):\n",
    "    full_lines = []\n",
    "    datasets_text = {\n",
    "        'train': [],\n",
    "        'valid': [],\n",
    "        'test': [],\n",
    "    }\n",
    "    for jline in jsonlines.open(fname):\n",
    "        for split in datasets_text.keys():\n",
    "            for sentence in tqdm(jline[split]):\n",
    "                datasets_text[split].append(tokenize(sentence))\n",
    "        \n",
    "    return datasets_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VNFvKKjFerFs"
   },
   "outputs": [],
   "source": [
    "# wikitext = load_wikitext('/Users/Antonio/Downloads/wikitext2-sentencized.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6T1E5F8serFu"
   },
   "outputs": [],
   "source": [
    "# pkl.dump(wikitext['train'], open('wiki_train_tokenized.p','wb'))\n",
    "# pkl.dump(wikitext['valid'], open('wiki_val_tokenized.p', 'wb'))\n",
    "# pkl.dump(wikitext['test'], open('wiki_test_tokenized.p','wb'))\n",
    "# pkl.dump(wikitext, open('wiki_all_tokenized.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAqLStSCerFz"
   },
   "outputs": [],
   "source": [
    "def load_wiki_data(path):\n",
    "    wiki_train = pkl.load(open(path+'wiki_train_tokenized.p','rb'))\n",
    "    wiki_val = pkl.load(open(path+'wiki_val_tokenized.p','rb'))\n",
    "    wiki_test = pkl.load(open(path+'wiki_test_tokenized.p','rb'))\n",
    "    wiki_all = pkl.load(open(path+'wiki_all_tokenized.p','rb'))\n",
    "    \n",
    "    return wiki_train, wiki_val, wiki_test, wiki_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fPjtGRFerF2"
   },
   "outputs": [],
   "source": [
    "wiki_train, wiki_val, wiki_test, wiki_all = load_wiki_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mkKdXYvserF4"
   },
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self, datasets, include_valid=False):\n",
    "        self.tokens = []\n",
    "        self.ids = {}\n",
    "        self.counts = {}\n",
    "        \n",
    "        # add special tokens\n",
    "        self.add_token('<bos>')\n",
    "        self.add_token('<eos>')\n",
    "        self.add_token('<pad>')\n",
    "        self.add_token('<unk>')\n",
    "\n",
    "        for line in tqdm(datasets['train']):\n",
    "            for w in line:\n",
    "                self.add_token(w)\n",
    "                    \n",
    "        if include_valid is True:\n",
    "            for line in tqdm(datasets['valid']):\n",
    "                for w in line:\n",
    "                    self.add_token(w)\n",
    "                            \n",
    "    def add_token(self, w):\n",
    "        if w not in self.tokens:\n",
    "            self.tokens.append(w)\n",
    "            _w_id = len(self.tokens) - 1\n",
    "            self.ids[w] = _w_id\n",
    "            self.counts[w] = 1\n",
    "        else:\n",
    "            self.counts[w] += 1\n",
    "\n",
    "    def get_id(self, w):\n",
    "        return self.ids[w]\n",
    "    \n",
    "    def get_token(self, idx):\n",
    "        return self.tokens[idx]\n",
    "    \n",
    "    def decode_idx_seq(self, l):\n",
    "        return [self.tokens[i] for i in l]\n",
    "    \n",
    "    def encode_token_seq(self, l):\n",
    "        return [self.ids[i] if i in self.ids else self.ids['<unk>'] for i in l]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xXVFQ55perF6",
    "outputId": "da71d33a-0f83-41d9-a52a-3fa17c995f9a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78274/78274 [01:37<00:00, 800.05it/s] \n"
     ]
    }
   ],
   "source": [
    "# wiki_dict = Dictionary(wiki_all, include_valid = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XeV4I8C6erF8"
   },
   "outputs": [],
   "source": [
    "# pkl.dump(wiki_dict, open('wiki_dictionary.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4rj2DtxWerF-"
   },
   "source": [
    "# Included pickled `wiki_dict` to avoid creating object\n",
    "takes around 1.5 mins to create.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JKgrJeu0erF_"
   },
   "outputs": [],
   "source": [
    "wiki_dict = pkl.load(open(path+'wiki_dictionary.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1iKv5cIerGA"
   },
   "outputs": [],
   "source": [
    "def tokenize_dataset(datasets, dictionary, ngram_order=2):\n",
    "    tokenized_datasets = {}\n",
    "    for split, dataset in datasets.items():\n",
    "        _current_dictified = []\n",
    "        for l in tqdm(dataset):\n",
    "            l = ['<bos>']*(ngram_order-1) + l + ['<eos>']\n",
    "            encoded_l = dictionary.encode_token_seq(l)\n",
    "            _current_dictified.append(encoded_l)\n",
    "        tokenized_datasets[split] = _current_dictified\n",
    "        \n",
    "    return tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sN671kCherGC"
   },
   "outputs": [],
   "source": [
    "def pad_list_of_tensors(list_of_tensors, pad_token):\n",
    "    max_length = max([t.size(-1) for t in list_of_tensors])\n",
    "    padded_list = []\n",
    "    \n",
    "    for t in list_of_tensors:\n",
    "        padded_tensor = torch.cat([t, torch.tensor([[pad_token]*(max_length - t.size(-1))], dtype=torch.long)], dim = -1)\n",
    "        padded_list.append(padded_tensor)\n",
    "        \n",
    "    padded_tensor = torch.cat(padded_list, dim=0)\n",
    "    \n",
    "    return padded_tensor\n",
    "\n",
    "def pad_collate_fn(batch):\n",
    "    # batch is a list of sample tuples\n",
    "    input_list = [s[0] for s in batch]\n",
    "    target_list = [s[1] for s in batch]\n",
    "    \n",
    "    #pad_token = persona_dict.get_id('<pad>')\n",
    "    pad_token = 2\n",
    "    \n",
    "    input_tensor = pad_list_of_tensors(input_list, pad_token)\n",
    "    target_tensor = pad_list_of_tensors(target_list, pad_token)\n",
    "    \n",
    "    return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KiJAuRY5erGE"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, RandomSampler, SequentialSampler, DataLoader\n",
    "\n",
    "class TensoredDataset(Dataset):\n",
    "    def __init__(self, list_of_lists_of_tokens):\n",
    "        self.input_tensors = []\n",
    "        self.target_tensors = []\n",
    "        \n",
    "        for sample in list_of_lists_of_tokens:\n",
    "            self.input_tensors.append(torch.tensor([sample[:-1]], dtype=torch.long))\n",
    "            self.target_tensors.append(torch.tensor([sample[1:]], dtype=torch.long))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_tensors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # return a (input, target) tuple\n",
    "        return (self.input_tensors[idx], self.target_tensors[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WeSHZLLperGF"
   },
   "outputs": [],
   "source": [
    "def build_ngram_loader(dataset, dataset_dict, ngram_order, batch_size=2048):\n",
    "    tokenized_ngram_dataset = tokenize_dataset(dataset, dataset_dict, ngram_order)\n",
    "    #sliced_ngram = slice_sequences_given_order(tokenized_ngram_dataset, ngram_order)\n",
    "\n",
    "    ngram_datasets = {}\n",
    "    ngram_loaders = {}\n",
    "    for split, tokenized_dataset in tokenized_ngram_dataset.items():\n",
    "        ngram_datasets[split] = TensoredDataset(tokenized_dataset)\n",
    "    \n",
    "    for split, tensored_dataset in ngram_datasets.items():\n",
    "        ngram_loaders[split] = DataLoader(tensored_dataset, batch_size=batch_size, shuffle=True,\\\n",
    "                                          collate_fn=pad_collate_fn)\n",
    "    return ngram_datasets, ngram_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "8K92PtdzerGJ",
    "outputId": "0a9d84b9-f7ae-42b0-cd05-211b45c6b474"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78274/78274 [00:00<00:00, 91408.70it/s] \n",
      "100%|██████████| 8464/8464 [00:00<00:00, 118265.13it/s]\n",
      "100%|██████████| 9708/9708 [00:00<00:00, 119083.04it/s]\n"
     ]
    }
   ],
   "source": [
    "wiki_datasets, wiki_loaders = build_ngram_loader(wiki_all, wiki_dict, 4, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "64Ui351c1-Fk"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrIbhglGerGN"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"\n",
    "    This model combines embedding, rnn and projection layer into a single model\n",
    "    \"\"\"\n",
    "    def __init__(self, options):\n",
    "        super().__init__()\n",
    "        \n",
    "        # create each LM part here \n",
    "        self.lookup = nn.Embedding(num_embeddings=options['num_embeddings'], embedding_dim=options['embedding_dim'], padding_idx=options['padding_idx'])\n",
    "        self.lstm = nn.LSTM(options['input_size'], options['hidden_size'], options['num_layers'], dropout=options['rnn_dropout'], batch_first=True)\n",
    "        self.projection = nn.Linear(options['hidden_size'], options['num_embeddings'])\n",
    "        \n",
    "    def forward(self, encoded_input_sequence):\n",
    "        \"\"\"\n",
    "        Forward method process the input from token ids to logits\n",
    "        \"\"\"\n",
    "        embeddings = self.lookup(encoded_input_sequence)\n",
    "        lstm_outputs = self.lstm(embeddings)\n",
    "        logits = self.projection(lstm_outputs[0])\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UqGD7dwerGP"
   },
   "outputs": [],
   "source": [
    "# check out eventually; below values are from lab 4\n",
    "# embedding_size = 256\n",
    "# hidden_size = 512\n",
    "# num_layers = 3\n",
    "# rnn_dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "010w_DpGerGS"
   },
   "outputs": [],
   "source": [
    "### values included here are BASELINE only\n",
    "hidden_size = 128\n",
    "embedding_size = 64\n",
    "rnn_dropout = 0.1\n",
    "num_layers = 2\n",
    "\n",
    "options = {\n",
    "        'num_embeddings': len(wiki_dict),\n",
    "        'embedding_dim': embedding_size,\n",
    "        'padding_idx': wiki_dict.get_id('<pad>'),\n",
    "        'input_size': embedding_size,\n",
    "        'hidden_size': hidden_size,\n",
    "        'num_layers': num_layers,\n",
    "        'rnn_dropout': rnn_dropout,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m16OksoXerGU"
   },
   "outputs": [],
   "source": [
    "lstm_model = LSTMModel(options).to(current_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzItUEZBerGW"
   },
   "outputs": [],
   "source": [
    "learn_rate = 0.001\n",
    "lstm_criterion = nn.CrossEntropyLoss(ignore_index=wiki_dict.get_id('<pad>'))\n",
    "\n",
    "# lstm_model_parameters = [p for p in lstm_model.parameters() if p.requires_grad]\n",
    "lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=learn_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Sw7FhqserGY"
   },
   "source": [
    "### Refactor for efficiency!\n",
    "in addition, may want to refactor similar to the way the lab implements this loop, where we allow for a pretrained model, i.e. we can provide a pretrained model to simply evaluate against validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_3wTEt1-of6"
   },
   "source": [
    "RENAME `lstm_perplexity` maybe _perplexity_ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rY-VVNITq47s"
   },
   "outputs": [],
   "source": [
    "def lstm_perplexity(ce_loss):\n",
    "  return (2**(ce_loss/np.log(2)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKpFmj3serGZ"
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "def train_lstm(model, loaders_dict, criterion, optimizer, path_to_save = path+'baseline_lstm.pt'):\n",
    "    start_time = dt.datetime.now()\n",
    "    print('{} | Starting training'.format(start_time))\n",
    "    \n",
    "    \n",
    "    plot_cache = []\n",
    "    best_perplexity = float('Inf')\n",
    "    \n",
    "    for epoch_number in range(10):\n",
    "        print('{} | Epoch {}'.format(dt.datetime.now(), epoch_number+1))\n",
    "        \n",
    "        avg_loss = -1.0\n",
    "        model.train()\n",
    "        train_log_cache = []\n",
    "        \n",
    "            #for i, (inp, target) in enumerate(persona_ngram_loaders['train']):\n",
    "        for i, (inp, target) in enumerate(loaders_dict['train']):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            inp = inp.to(current_device)\n",
    "            target = target.to(current_device)\n",
    "            logits = model(inp)\n",
    "\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_log_cache.append(loss.item())  \n",
    "        \n",
    "            if i % 100 == 0: \n",
    "              print('{} | Number steps {}'.format(dt.datetime.now(), i))\n",
    "                \n",
    "        avg_loss = sum(train_log_cache)/len(train_log_cache)\n",
    "        print('{} | Epoch {} avg train loss = {:.{prec}f}'.format(dt.datetime.now(), epoch_number+1, avg_loss, prec=4))\n",
    "     \n",
    "        train_log_cache = []\n",
    "      \n",
    "        #do valid\n",
    "        valid_losses = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (inp, target) in enumerate(loaders_dict['valid']):\n",
    "\n",
    "                inp = inp.to(current_device)\n",
    "                target = target.to(current_device)\n",
    "                logits = model(inp)\n",
    "                loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
    "                valid_losses.append(loss.item())\n",
    "            avg_val_loss = sum(valid_losses) / len(valid_losses)\n",
    "            print('Epoch {} validation loss = {:.{prec}f}'.format(epoch_number+1, avg_val_loss, prec=4))\n",
    "\n",
    "            plot_cache.append((avg_loss, avg_val_loss))\n",
    "            val_ppl = lstm_perplexity(avg_val_loss)\n",
    "            print('Epoch {}, perplexity achieved {}'.format(epoch_number+1, val_ppl))\n",
    "            if val_ppl < best_perplexity:\n",
    "              torch.save(model.state_dict(), path_to_save)\n",
    "              best_perplexity = val_ppl\n",
    "    print('{} | Finished training in {}'.format(dt.datetime.now(), dt.datetime.now() - start_time))\n",
    "          \n",
    "    return plot_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bhmLiUZ9erGb"
   },
   "outputs": [],
   "source": [
    "lstm_losses = train_lstm(lstm_model, wiki_loaders, lstm_criterion, lstm_optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "2jahfn5y79Fy",
    "outputId": "5bde4ff3-28ad-4ec1-9d20-90619bbc1396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, perplexity 485.74431725177425 \n",
      "Epoch 2, perplexity 340.5988893900643 \n",
      "Epoch 3, perplexity 282.0407894433271 \n",
      "Epoch 4, perplexity 248.94715152003695 \n",
      "Epoch 5, perplexity 227.81834640900593 \n",
      "Epoch 6, perplexity 211.63231959516264 \n",
      "Epoch 7, perplexity 202.8889041485416 \n",
      "Epoch 8, perplexity 195.41396969511615 \n",
      "Epoch 9, perplexity 189.1255822014498 \n",
      "Epoch 10, perplexity 185.00784711463538 \n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(lstm_losses):\n",
    "    print('Epoch {}, perplexity {} '.format(i+1,lstm_perplexity(j[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErCKgfq39ZVA"
   },
   "outputs": [],
   "source": [
    "pkl.dump(lstm_losses, open('baseline_lstm_losses.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QyimPD-17HP"
   },
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Mp-ARgg15ZN"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"\n",
    "    This model combines embedding, rnn and projection layer into a single model\n",
    "    \"\"\"\n",
    "    def __init__(self, options):\n",
    "        super().__init__()\n",
    "        \n",
    "        # create each LM part here \n",
    "        self.lookup = nn.Embedding(num_embeddings=options['num_embeddings'], embedding_dim=options['embedding_dim'], padding_idx=options['padding_idx'])\n",
    "        self.rnn = nn.RNN(options['input_size'], options['hidden_size'], options['num_layers'], dropout=options['rnn_dropout'], batch_first=True)\n",
    "        self.projection = nn.Linear(options['hidden_size'], options['num_embeddings'])\n",
    "        \n",
    "    def forward(self, encoded_input_sequence):\n",
    "        \"\"\"\n",
    "        Forward method process the input from token ids to logits\n",
    "        \"\"\"\n",
    "        embeddings = self.lookup(encoded_input_sequence)\n",
    "        rnn_outputs = self.rnn(embeddings)\n",
    "        logits = self.projection(rnn_outputs[0])\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vnrqhjEu7OCn"
   },
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    current_device = 'cuda'\n",
    "    path = 'gdrive/My Drive/'\n",
    "else:\n",
    "    current_device = 'cpu'\n",
    "    path = './'\n",
    "\n",
    "rnn_model = RNNModel(options).to(current_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w6IDaJ6O157U"
   },
   "outputs": [],
   "source": [
    "learn_rate = 0.001\n",
    "rnn_criterion = nn.CrossEntropyLoss(ignore_index=wiki_dict.get_id('<pad>'))\n",
    "\n",
    "# lstm_model_parameters = [p for p in lstm_model.parameters() if p.requires_grad]\n",
    "rnn_optimizer = optim.Adam(rnn_model.parameters(), lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PdSFddoQ2OWh"
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "def train_rnn(model, loaders_dict, criterion, optimizer, path_to_save = path+'baseline_rnn.pt'):\n",
    "    start_time = dt.datetime.now()\n",
    "    print('{} | Starting training'.format(start_time))\n",
    "    \n",
    "    \n",
    "    plot_cache = []\n",
    "    best_perplexity = float('Inf')\n",
    "    \n",
    "    for epoch_number in range(10):\n",
    "        print('{} | Epoch {}'.format(dt.datetime.now(), epoch_number+1))\n",
    "        \n",
    "        avg_loss = -1.0\n",
    "        model.train()\n",
    "        train_log_cache = []\n",
    "        \n",
    "            #for i, (inp, target) in enumerate(persona_ngram_loaders['train']):\n",
    "        for i, (inp, target) in enumerate(loaders_dict['train']):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            inp = inp.to(current_device)\n",
    "            target = target.to(current_device)\n",
    "            logits = model(inp)\n",
    "\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_log_cache.append(loss.item())  \n",
    "        \n",
    "            if i % 100 == 0: \n",
    "              print('{} | Number steps {}'.format(dt.datetime.now(), i))\n",
    "                \n",
    "        avg_loss = sum(train_log_cache)/len(train_log_cache)\n",
    "        print('{} | Epoch {} avg train loss = {:.{prec}f}'.format(dt.datetime.now(), epoch_number+1, avg_loss, prec=4))\n",
    "     \n",
    "        train_log_cache = []\n",
    "      \n",
    "        #do valid\n",
    "        valid_losses = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (inp, target) in enumerate(loaders_dict['valid']):\n",
    "\n",
    "                inp = inp.to(current_device)\n",
    "                target = target.to(current_device)\n",
    "                logits = model(inp)\n",
    "                loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
    "                valid_losses.append(loss.item())\n",
    "            avg_val_loss = sum(valid_losses) / len(valid_losses)\n",
    "            print('Epoch {} validation loss = {:.{prec}f}'.format(epoch_number+1, avg_val_loss, prec=4))\n",
    "\n",
    "            plot_cache.append((avg_loss, avg_val_loss))\n",
    "            \n",
    "            # Perplexity function is the same LSTM/RNN\n",
    "            val_ppl = lstm_perplexity(avg_val_loss)\n",
    "            print('Epoch {}, perplexity achieved {}'.format(epoch_number+1, val_ppl))\n",
    "            if val_ppl < best_perplexity:\n",
    "              torch.save(model.state_dict(), path_to_save)\n",
    "              best_perplexity = val_ppl\n",
    "    print('{} | Finished training in {}'.format(dt.datetime.now(), dt.datetime.now() - start_time))\n",
    "          \n",
    "    return plot_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1u5M1DNd2Og1",
    "outputId": "24eef1c9-0448-4a16-fe1d-4b476eb24b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-02 01:00:27.574590 | Starting training\n",
      "2019-10-02 01:00:27.576968 | Epoch 1\n",
      "2019-10-02 01:00:27.878605 | Number steps 0\n",
      "2019-10-02 01:00:47.922668 | Number steps 100\n",
      "2019-10-02 01:01:08.081708 | Number steps 200\n",
      "2019-10-02 01:01:28.989724 | Number steps 300\n",
      "2019-10-02 01:01:48.858173 | Number steps 400\n",
      "2019-10-02 01:02:08.982005 | Number steps 500\n",
      "2019-10-02 01:02:29.433522 | Number steps 600\n",
      "2019-10-02 01:02:31.459611 | Epoch 1 avg train loss = 6.4174\n",
      "Epoch 1 validation loss = 5.7755\n",
      "Epoch 1, perplexity achieved 322.2948576543607\n",
      "2019-10-02 01:02:37.076556 | Epoch 2\n",
      "2019-10-02 01:02:37.323707 | Number steps 0\n",
      "2019-10-02 01:02:57.181535 | Number steps 100\n",
      "2019-10-02 01:03:17.869424 | Number steps 200\n",
      "2019-10-02 01:03:38.507705 | Number steps 300\n",
      "2019-10-02 01:03:58.383793 | Number steps 400\n",
      "2019-10-02 01:04:18.900043 | Number steps 500\n",
      "2019-10-02 01:04:39.431193 | Number steps 600\n",
      "2019-10-02 01:04:41.610963 | Epoch 2 avg train loss = 5.8439\n",
      "Epoch 2 validation loss = 5.5393\n",
      "Epoch 2, perplexity achieved 254.4936345621147\n",
      "2019-10-02 01:04:47.122766 | Epoch 3\n",
      "2019-10-02 01:04:47.409798 | Number steps 0\n",
      "2019-10-02 01:05:07.536133 | Number steps 100\n",
      "2019-10-02 01:05:28.041639 | Number steps 200\n",
      "2019-10-02 01:05:48.563481 | Number steps 300\n",
      "2019-10-02 01:06:09.088268 | Number steps 400\n",
      "2019-10-02 01:06:29.200367 | Number steps 500\n",
      "2019-10-02 01:06:49.677177 | Number steps 600\n",
      "2019-10-02 01:06:51.782910 | Epoch 3 avg train loss = 5.6222\n",
      "Epoch 3 validation loss = 5.4184\n",
      "Epoch 3, perplexity achieved 225.51756898122392\n",
      "2019-10-02 01:06:57.341098 | Epoch 4\n",
      "2019-10-02 01:06:57.603796 | Number steps 0\n",
      "2019-10-02 01:07:18.308400 | Number steps 100\n",
      "2019-10-02 01:07:39.394379 | Number steps 200\n",
      "2019-10-02 01:07:59.097621 | Number steps 300\n",
      "2019-10-02 01:08:19.061231 | Number steps 400\n",
      "2019-10-02 01:08:39.515459 | Number steps 500\n",
      "2019-10-02 01:08:59.731878 | Number steps 600\n",
      "2019-10-02 01:09:01.727749 | Epoch 4 avg train loss = 5.4724\n",
      "Epoch 4 validation loss = 5.3474\n",
      "Epoch 4, perplexity achieved 210.06139386190586\n",
      "2019-10-02 01:09:07.263611 | Epoch 5\n",
      "2019-10-02 01:09:07.472265 | Number steps 0\n",
      "2019-10-02 01:09:27.859325 | Number steps 100\n",
      "2019-10-02 01:09:47.798896 | Number steps 200\n",
      "2019-10-02 01:10:07.867984 | Number steps 300\n",
      "2019-10-02 01:10:28.162717 | Number steps 400\n",
      "2019-10-02 01:10:49.485603 | Number steps 500\n",
      "2019-10-02 01:11:09.740574 | Number steps 600\n",
      "2019-10-02 01:11:11.833110 | Epoch 5 avg train loss = 5.3585\n",
      "Epoch 5 validation loss = 5.2987\n",
      "Epoch 5, perplexity achieved 200.07688413138428\n",
      "2019-10-02 01:11:17.393400 | Epoch 6\n",
      "2019-10-02 01:11:17.565598 | Number steps 0\n",
      "2019-10-02 01:11:38.104433 | Number steps 100\n",
      "2019-10-02 01:11:58.406852 | Number steps 200\n",
      "2019-10-02 01:12:18.899583 | Number steps 300\n",
      "2019-10-02 01:12:39.112153 | Number steps 400\n",
      "2019-10-02 01:12:59.572414 | Number steps 500\n",
      "2019-10-02 01:13:20.089233 | Number steps 600\n",
      "2019-10-02 01:13:22.147864 | Epoch 6 avg train loss = 5.2662\n",
      "Epoch 6 validation loss = 5.2702\n",
      "Epoch 6, perplexity achieved 194.4521044977905\n",
      "2019-10-02 01:13:27.625372 | Epoch 7\n",
      "2019-10-02 01:13:27.796006 | Number steps 0\n",
      "2019-10-02 01:13:48.867700 | Number steps 100\n",
      "2019-10-02 01:14:09.112506 | Number steps 200\n",
      "2019-10-02 01:14:28.576901 | Number steps 300\n",
      "2019-10-02 01:14:48.717098 | Number steps 400\n",
      "2019-10-02 01:15:09.314089 | Number steps 500\n",
      "2019-10-02 01:15:29.573553 | Number steps 600\n",
      "2019-10-02 01:15:31.710508 | Epoch 7 avg train loss = 5.1889\n",
      "Epoch 7 validation loss = 5.2455\n",
      "Epoch 7, perplexity achieved 189.71565241530683\n",
      "2019-10-02 01:15:37.416269 | Epoch 8\n",
      "2019-10-02 01:15:37.576210 | Number steps 0\n",
      "2019-10-02 01:15:57.654077 | Number steps 100\n",
      "2019-10-02 01:16:17.872074 | Number steps 200\n",
      "2019-10-02 01:16:37.945232 | Number steps 300\n",
      "2019-10-02 01:16:58.290428 | Number steps 400\n",
      "2019-10-02 01:17:19.188182 | Number steps 500\n",
      "2019-10-02 01:17:39.413268 | Number steps 600\n",
      "2019-10-02 01:17:41.621161 | Epoch 8 avg train loss = 5.1229\n",
      "Epoch 8 validation loss = 5.2270\n",
      "Epoch 8, perplexity achieved 186.2382209449899\n",
      "2019-10-02 01:17:47.151646 | Epoch 9\n",
      "2019-10-02 01:17:47.426057 | Number steps 0\n",
      "2019-10-02 01:18:07.151126 | Number steps 100\n",
      "2019-10-02 01:18:27.684233 | Number steps 200\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b2e68e36d7e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnn_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwiki_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'baseline_rnn_losses.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-50f344a468d0>\u001b[0m in \u001b[0;36mtrain_rnn\u001b[0;34m(model, loaders_dict, criterion, optimizer, path_to_save)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.66 GiB (GPU 0; 11.17 GiB total capacity; 5.20 GiB already allocated; 1.41 GiB free; 4.24 GiB cached)"
     ]
    }
   ],
   "source": [
    "rnn_losses = train_rnn(rnn_model, wiki_loaders, rnn_criterion, rnn_optimizer)\n",
    "pkl.dump(rnn_losses, open('baseline_rnn_losses.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zq1aD3loD6jQ"
   },
   "outputs": [],
   "source": [
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97gvAHpLerGd"
   },
   "source": [
    "### II.1 LSTM and Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esNNWDIUerGd"
   },
   "outputs": [],
   "source": [
    "def grid_search(emb_dims, dropouts):\n",
    "    \n",
    "    \n",
    "    \n",
    "    for emb_dim in emb_dims:\n",
    "        for dropout in dropouts:\n",
    "      \n",
    "            options = {\n",
    "                'num_embeddings': len(wiki_dict),\n",
    "                'embedding_dim': emb_dim,\n",
    "                'padding_idx': wiki_dict.get_id('<pad>'),\n",
    "                'input_size': emb_dim,\n",
    "                'hidden_size': hidden_size,\n",
    "                'num_layers': num_layers,\n",
    "                'rnn_dropout': dropout,\n",
    "            }\n",
    "            lstm_model = LSTMModel(options).to(current_device)\n",
    "            lstm_losses = train_lstm(lstm_model, wiki_loaders, lstm_criterion, lstm_optimizer, path+ \"emb_dim=\" + str(emb_dim) + \"_dropout=\" + str(dropout) + \".pt\")\n",
    "            pkl.dump(lstm_losses, open(path+ \"emb_dim=\" + str(emb_dim) +  \"_dropout=\" + str(dropout) + \".p\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qL2QPU8terGf"
   },
   "source": [
    "#### Results (LSTM vs. Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9vX-91TerGg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xz5l25EperGh"
   },
   "source": [
    "#### Performance Variation Based on Hyperparameter Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yMlxEDtierGi"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "models_dir = [file for file in os.listdir(path+'Grid Search/') if file.endswith('.p')]\n",
    "models_dir.sort()\n",
    "perplexities = []\n",
    "names = []\n",
    "%matplotlib inline\n",
    "for file in models_dir:\n",
    "    ppl_file = pkl.load(open(path+'Grid Search/'+file,'rb'))\n",
    "    perplexities.append(lstm_perplexity(ppl_file[-1][1]))\n",
    "    emb_d = re.search(r'(?<=\\=)\\d+', file).group(0)\n",
    "    drop_out = re.search(r'(?<=\\=)\\d\\.\\d', file).group(0)\n",
    "    names.append(emb_d + '\\n'+ drop_out)\n",
    "\n",
    "x_pos = range(len(perplexities))\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.bar(x_pos, perplexities, align='center', alpha=0.5)\n",
    "plt.xticks(x_pos, names)\n",
    "plt.ylabel('Validation Perplexity')\n",
    "plt.xlabel('Embedding Dimension\\nDrop out Probability')\n",
    "plt.title('Validation Perplexity for each (embedding dimension, dropout) hyper-parameter pair')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "01x_Q25GerGk"
   },
   "source": [
    "### II.2 Learned Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivqkICEkerGk"
   },
   "source": [
    "#### Utilities\n",
    "\n",
    "Below is code to use [UMAP](https://umap-learn.readthedocs.io/en/latest/) to find a 2-dimensional representation of a weight matrix, and plot the resulting 2-dimensional points that correspond to certain words.\n",
    "\n",
    "Use `!pip install umap-learn` to install UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqTr_62RerGl",
    "outputId": "31658b4d-2f00-4613-ea47-1cf5877cb79b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline \n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def umap_plot(weight_matrix, word_ids, words):\n",
    "    \"\"\"Run UMAP on the entire Vxd `weight_matrix` (e.g. model.lookup.weight or model.projection.weight),\n",
    "    And plot the points corresponding to the given `word_ids`. \"\"\"\n",
    "    reduced = umap.UMAP(min_dist=0.0001).fit_transform(weight_matrix.detach().cpu().numpy())\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    to_plot = reduced[word_ids, :]\n",
    "    plt.scatter(to_plot[:, 0], to_plot[:, 1])\n",
    "    for i, word_id in enumerate(word_ids):\n",
    "        current_point = to_plot[i]\n",
    "        plt.annotate(words[i], (current_point[0], current_point[1]))\n",
    "\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5IWEkSzDerGn",
    "outputId": "53524f1e-e732-4b10-f17b-10c1eb8d9dae"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Vsize = 100                                 # e.g. len(dictionary)\n",
    "d = 32                                      # e.g. model.lookup.weight.size(1) \n",
    "fake_weight_matrix = torch.randn(Vsize, d)  # e.g. model.lookup.weight\n",
    "\n",
    "words = ['the', 'dog', 'ran']\n",
    "word_ids = [4, 54, 20]                  # e.g. use dictionary.get_id on a list of words\n",
    "\n",
    "umap_plot(fake_weight_matrix, word_ids, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OtBe0FmgerGo"
   },
   "source": [
    "#### II.2.1 Word Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YuNafa2erGp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OJL5XRpDerGq"
   },
   "source": [
    "#### II.2.2 Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7sMAajEerGr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1WMSHRA6erGu"
   },
   "source": [
    "#### II.2.3 Projection Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42ejnL7AerGu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ycvS0PEberGx"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WxqEAO4IerGy"
   },
   "source": [
    "### II.3 Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwoHDo4xerGy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "58wLi3TIerG0"
   },
   "source": [
    "#### II.3.2 Highest and Lowest scoring sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S77x0WAOerG1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6lm2RPZerG3"
   },
   "source": [
    "#### II.3.3 Modified sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDlWT7pverG4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ygWd_A72erG5"
   },
   "source": [
    "### II.4 Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading best trained model-- embedding dimension: 128, dropout: 0.1\n",
    "\n",
    "Below is included simply for initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JBqVQMHKerG6"
   },
   "outputs": [],
   "source": [
    "stock_hidden_size = 128\n",
    "stock_embedding_size = 128\n",
    "stock_rnn_dropout = 0.1\n",
    "stock_num_layers = 2\n",
    "\n",
    "stock_options = {\n",
    "        'num_embeddings': len(wiki_dict),\n",
    "        'embedding_dim': stock_embedding_size,\n",
    "        'padding_idx': wiki_dict.get_id('<pad>'),\n",
    "        'input_size': stock_embedding_size,\n",
    "        'hidden_size': stock_hidden_size,\n",
    "        'num_layers': stock_num_layers,\n",
    "        'rnn_dropout': stock_rnn_dropout,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lookup): Embedding(28792, 128, padding_idx=2)\n",
       "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (projection): Linear(in_features=128, out_features=28792, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path = path+'Grid Search/emb_dim=128_dropout=0.1.pt'\n",
    "best_lstm = LSTMModel(stock_options).to(current_device)\n",
    "if current_device == 'cpu':\n",
    "    model_checkpoint = torch.load(best_model_path, map_location=torch.device(current_device))\n",
    "else:\n",
    "    model_checkpoint = torch.load(best_model_path+'Grid Search/emb_dim=128_dropout=0.1.pt')\n",
    "\n",
    "best_lstm.load_state_dict(model_checkpoint)\n",
    "best_lstm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on `generate_sentences()`\n",
    "Due to the fact that we built our RNN and LSTM models on n-grams, specifically 4-grams, it was not possible to simply pass a single token to our pretrained model at each iteration of the innermost `while`-loop. When passing a single word/token, what is returned is a high likelihood of `<bos>` following our currently fed word rather than continuing through the sequence/sentence. Remember that this is due to the fact that we padded the start of our n-grams with `<bos>` a total of $(n-1)$ times. Furthermore, this is a result of how we defined our **target** classes--see the class `TensoredDataset` for more info. To be more specific, our inputs and our targets were **both** sequences.\n",
    "\n",
    "So instead of passing individual tokens, we proceed by appending each generated word to a tensor named `sentence`. The growing tensor is fed back into our model _until_ the next word that is generated is `<eos>`, at which point we consider the sentence generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_sentences(model, vocabulary, total_sentences=1000):\n",
    "    all_sentences = []\n",
    "    with tqdm(total=total_sentences) as pbar:\n",
    "        while len(all_sentences) < total_sentences:\n",
    "            first_word_idx = [vocabulary.get_id('<bos>')]\n",
    "            first_word_tensor = torch.LongTensor([first_word_idx])\n",
    "            sentence = torch.LongTensor([first_word_idx])\n",
    "            first_elem_passed = False\n",
    "            eos = False\n",
    "            while not eos:\n",
    "                seq_out = model(sentence)\n",
    "                word_prob = F.softmax(seq_out, dim = 2).squeeze()\n",
    "                if len(word_prob.size()) > 1: \n",
    "                    word_prob = word_prob[word_prob.size()[0] - 1 ]\n",
    "\n",
    "                word = torch.multinomial(word_prob, num_samples = 1)\n",
    "                word = int(word.data[-1:])\n",
    "                if word == vocabulary.get_id('<eos>'):\n",
    "                    eos = True\n",
    "                word = torch.tensor([word], dtype = torch.long)\n",
    "                sentence = torch.cat((sentence.squeeze(0), word))    \n",
    "                sentence = sentence.expand(1,sentence.size()[0])\n",
    "            all_sentences.append(vocabulary.decode_idx_seq([int(i) for i in sentence.squeeze()]))\n",
    "            pbar.update(1)\n",
    "    return all_sentences\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:21<00:00,  4.09it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences_1000 = generate_sentences(best_lstm, wiki_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(sentences_1000, open('one_thousand_sentences.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_1000 = pkl.load(open(path+'one_thousand_sentences.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>',\n",
       " '<bos>',\n",
       " '<bos>',\n",
       " 'he',\n",
       " 'added',\n",
       " 'that',\n",
       " 'she',\n",
       " 'expressed',\n",
       " 'unlike',\n",
       " 'the',\n",
       " 'abrupt',\n",
       " 'cup',\n",
       " 'arrangements',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_1000[199]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ID5eiL5JerG7"
   },
   "source": [
    "#### II.4.3 Number of unique tokens and sequence length \n",
    "\n",
    "(1,000 samples vs. 1,000 randomly selected validation-set sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMLc8_k6erG9"
   },
   "source": [
    "#### II.4.4 Example Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulJU-uFverG-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6QzTPpkRerFf",
    "R2n6VrfCerFi",
    "qL2QPU8terGf",
    "Xz5l25EperGh",
    "01x_Q25GerGk",
    "ivqkICEkerGk",
    "OtBe0FmgerGo",
    "OJL5XRpDerGq",
    "1WMSHRA6erGu",
    "WxqEAO4IerGy",
    "58wLi3TIerG0",
    "t6lm2RPZerG3",
    "ygWd_A72erG5",
    "ID5eiL5JerG7",
    "bMLc8_k6erG9"
   ],
   "name": "antonio_RNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
